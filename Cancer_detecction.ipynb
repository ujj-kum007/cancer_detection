{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cancer_detecction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bz9qU4aA6jKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.layers.core import Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxIz5vAS6uu3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_path = 'base_dir/train_dir'\n",
        "valid_path = 'base_dir/val_dir'\n",
        "num_train_samples = 9013\n",
        "num_val_samples = 1002\n",
        "train_batch_size = 10\n",
        "val_batch_size = 10\n",
        "image_size = 224\n",
        "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
        "val_steps = np.ceil(num_val_samples / val_batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVy82zbe60ED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_batches = ImageDataGenerator(\n",
        "    preprocessing_function= keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=train_batch_size) \n",
        "\n",
        "valid_batches = ImageDataGenerator(\n",
        "    preprocessing_function= keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
        "    valid_path,\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=val_batch_size)\n",
        "\n",
        "test_batches = ImageDataGenerator(\n",
        "    preprocessing_function= keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
        "    valid_path,\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=val_batch_size,\n",
        "    shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wVqRE5w63RJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
        "\n",
        "def top_3_accuracy(y_true, y_pred):\n",
        "    return top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
        "\n",
        "def top_2_accuracy(y_true, y_pred):\n",
        "    return top_k_categorical_accuracy(y_true, y_pred, k=2)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(Adam(lr=0.01), loss='categorical_crossentropy', metrics=[categorical_accuracy, top_2_accuracy, top_3_accuracy])\n",
        "\n",
        "# Add weights to make the model more sensitive to melanoma\n",
        "class_weights={\n",
        "    0: 1.0,  # akiec\n",
        "    1: 1.0,  # bcc\n",
        "    2: 1.0,  # bkl\n",
        "    3: 1.0,  # df\n",
        "    4: 3.0,  # mel\n",
        "    5: 1.0,  # nv\n",
        "    6: 1.0,  # vasc\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Zm-Q3Nk661f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath = \"model.h5\"\n",
        "\n",
        "# Declare a checkpoint to save the best version of the model\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_top_3_accuracy', verbose=1,\n",
        "                             save_best_only=True, mode='max')\n",
        "\n",
        "# Reduce the learning rate as the learning stagnates\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_top_3_accuracy', factor=0.5, patience=2,\n",
        "                              verbose=1, mode='max', min_lr=0.00001)\n",
        "\n",
        "callbacks_list = [checkpoint, reduce_lr]\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit_generator(train_batches,\n",
        "                              steps_per_epoch=train_steps,\n",
        "                              class_weight=class_weights,\n",
        "                              validation_data=valid_batches,\n",
        "                              validation_steps=val_steps,\n",
        "                              epochs=10,\n",
        "                              verbose=1,\n",
        "                              callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}